---
title: "Exercício Computacional I"
author: "Anderson Ganhara"
date: "6/20/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Contexto do problema: Temos o objetivo de construir um modelo preditivo de ML baseado em Redes Neurais
Artificiais (RNAs) que seja capaz de realizar predições dos valores medianos de preços das casas em uma região
suburbana de Boston, EUA. Tal como no caso da regressão linear, a variável a ser predita consiste em um valor
numérico que representa o preço mediano das casas. Para cada uma das observações, temos diversas variáveis de
entrada. Logo, podemos buscar a solução para esse problema usando diferentes técnicas de Machine Learning:
nesse caso iremos construir, treinar e testar uma rede neural artificial para fazer as predições.
O pacote neuralnet pode ser usado para construirmos o modelo de RNA. Na linguagem R podemos usar:
install.packages("neuralnet")
library(neuralnet)
Dataset: Os dados estão fornecidos na forma de tabela (.xlsx e .csv) retratado pelo dataset Boston, presente na
biblioteca MASS do software R que apresenta os valores das casas (Median value of owner-occupied homes)
em 506 vizinhanças da cidade de Boston. Os dados que acompanham o valor mediano dos preços das casas
consistem em indicadores de condições socioeconômicas, ambientais, instalações educacionais e alguns outros
fatores semelhantes. No ambiente R, o comando ?Boston fornece informações sobre cada uma das features.
Ao todo, são 13 features e uma variável resposta, denotada como medv (preço mediano da casa), baseada em
$1,000 dólares. De forma específica, no conjunto de variáveis explanatórias (i.e., características), temos doze
(12) variáveis numéricas e uma (1) variável categórica, que no caso pode assumir 0 (zero) ou 1 (um). Com
isso, a planilha de dados apresenta 506 linhas (exemplos de treinamento) e 14 colunas (features). Abaixo, estão
colocadas cada uma das variáveis características do dataset e seu respectivo significado:
• CRIM: per capita crime rate by town
• ZN: proportion of residential land zoned for lots over 25,000 sq.ft.
• INDUS: proportion of non-retail business acres per town
• CHAS: Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)
• NOX: nitric oxides concentration (parts per 10 million)
• RM: average number of rooms per dwelling
• AGE: proportion of owner-occupied units built prior to 1940
• DIS: weighted distances to five Boston employment centres
• RAD: index of accessibility to radial highways
• TAX: full-value property-tax rate per 10,000
• PTRATIO: pupil-teacher ratio by town
• B: 1000(Bk −0.63)
2 where Bk is the proportion of blacks by town
• LSTAT: % lower status of the population
• TARGET: Median value of owner-occupied homes in $1000’s
Abaixo, seguem os itens que devemos solucionar, visando alcançar o objetivo deste exercício:
```{r}
library(MASS)
library(neuralnet)
library(caTools)
library(ggplot2)
library(plotly)
library(tidyverse)
dataset <- Boston
```


• Questões Avaliativas

– 1) Faça a exploração dos dados bem como síntese sobre suas principais variáveis explanatórias.
```{r}
str(dataset)
```

```{r}
summary(dataset)
```

Verificando a existencia de NAS

```{r}
any(is.na(dataset))
```

– 2) Realize o procedimento de normalização mínimo-máximo sobre as características do dataframe

```{r}
?apply
# Procedimento de Normalização min/max - vamos capturar os valores máximo e mínimo dos dados
maximo <- apply(dataset, 2, max) 
minimo <- apply(dataset, 2, min)

# Dica:
# i) é importante observar atentamente cada variável explanatória do dataset para aplicarmos a 
# função apply ao conjunto de dados inteiro. 

# Imprimindo os valores
maximo
minimo
View(dataset)
```


```{r}
# Aplicando a normalização min/max (função scale - pacote RBase)
dados_normalizados <- as.data.frame(scale(dataset, center = minimo, scale = maximo - minimo))
head(dados_normalizados)
```



– 3) Para reprodução dos resultados use o set.seed(12).
```{r}
set.seed(12)
```


– 4) Realize a divisão do conjunto de treino e teste em 70/30.
```{r}
# =====================================================================================
# Fazendo a divisão dos dados em conjuntos de treinamento e teste

# Aplicando a função sample.split (pacote caTools) para divisão dos dados
# O sample.split é mais uma maneira de gerarmos índices para, posteriormente, 
# acessarmos o dataset e realizamos a divisão treino/teste
divisao_dados = sample.split(dados_normalizados$medv, SplitRatio = 0.70)
# Acessando o conjunto de dados de treinamento com a função subset
dados_norm_treinamento = subset(dados_normalizados, divisao_dados == TRUE)
dados_norm_teste       = subset(dados_normalizados, divisao_dados == FALSE)
```


– 5) Construa e treine o modelo preditivo de ML baseado em redes neurais artificiais.

```{r}
# Capturando os nomes das colunas
nomes_colunas <- colnames(dados_norm_treinamento)
nomes_colunas

# Vamos usar os nomes das variáveis explanatórias na montagem do objeto do tipo fórmula do R
equation_model <- as.formula(paste ( "medv ~ ", paste(nomes_colunas[!nomes_colunas %in% "medv"], collapse = " + ")))
equation_model

# Treinamento com NeuralNet - repare estamos 
?neuralnet
modelo_RNA = neuralnet(equation_model, data = dados_norm_treinamento, hidden = c(5,3), linear.output = TRUE)
modelo_RNA
```


– 6) Visualize a arquitetura da RNA treinada
```{r}
plot(modelo_RNA)
```


– 7) Aplique o modelo sobre os dados de teste para geração de predições
```{r}
# ==========================================================
# Fazendo predições com a rede neural treinada 
?compute
# Vamos usar a função compute (do pacote neural net)
RNA_pred_norm = neuralnet::compute(modelo_RNA, dados_norm_teste[1:13])
RNA_pred_norm
```

```{r}
# É importante notar que as predições foram obtidas a partir dos dados de teste normalizados. 
# Precisamos fazer a conversão de normalização necessária para acessar os valores previstos de interesse


# Como fazer a conversão de normalização no caso de min/max

# 1) Acessamos a rede neural treinada e seu resultado ($net.result)
# 2) Acessamos os valores da variável de saída (medv) 
# 3) Multiplicamos os resultados normalizados pela diferença entre o máximo e o mínimo - e acrescentamos o mínimo
max_medv = max(dataset$medv) 
min_medv = min(dataset$medv)
#Dados obtidos da rede neural
RNA_pred = RNA_pred_norm$net.result*(max_medv - min_medv) + min_medv

# Vamos fazer o mesmo procedimento para os dados de teste normalizados
dados_teste <- (dados_norm_teste$medv)*(max_medv - min_medv) +  min_medv
dados_teste
```

– 8) Forneça a estimativa de erro quadrático médio (MSE)
```{r}
# ----------------------------------------------------------------------------
# Estimativa do Erro Quadrático Médio (MSE - Mean Squared Error) do Modelo RNA
MSE_RNA <- sum(     ((dados_teste - RNA_pred)^2) )/nrow(RNA_pred)
MSE_RNA

# Obtendo os erros de previsao
df_RNA_pred <- data.frame(dados_teste, RNA_pred)
# head(df_RNA_pred)

```


– 9) Compare os resultados de predição com os dados de teste (graficamente)
```{r}
# Plot dos erros
chart <- ggplot(df_RNA_pred, aes(x = dados_teste,y = RNA_pred)) + 
            geom_point() + 
            stat_smooth() + 
            xlab('Dados de Teste (preço mediano das casas)') + 
            ylab('Predições')  +
            ggtitle("Gráfico de Desempenho - Modelo RNA")
chart
#plotly::ggplotly(chart)
```

